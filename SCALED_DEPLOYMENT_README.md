# üöÄ CustomerCareGPT Scaled System

## Overview

This is the **scaled version** of CustomerCareGPT designed to handle **300+ business owners** with **5,000+ customers** and **30,000-50,000 queries per day** while maintaining high performance and reliability.

## üéØ Performance Targets

- **Business Owners**: 300+
- **Customers**: 5,000+
- **Daily Queries**: 30,000-50,000
- **Concurrent Users**: 200+
- **RAG Response Time**: 1-3 seconds
- **File Processing**: 50-100 documents/minute
- **Uptime**: 99.9%

## üèóÔ∏è Architecture Enhancements

### Database Optimizations
- **Connection Pooling**: 50 write + 30 read connections per replica
- **Read Replicas**: Load-balanced read operations
- **Performance Indexes**: Optimized for common query patterns
- **Query Optimization**: Enhanced with proper indexing

### Caching Strategy
- **Redis Caching**: Multi-layer caching with TTL
- **Vector Search Cache**: 30-minute cache for search results
- **Analytics Cache**: 5-minute cache for analytics data
- **Session Cache**: 24-hour cache for user sessions

### Background Processing
- **Enhanced Workers**: 2 replicas with batching
- **Priority Queues**: High, normal, and low priority processing
- **Circuit Breakers**: Fault tolerance for external services
- **Batch Processing**: Efficient document and embedding processing

### Load Balancing
- **API Replicas**: 3 load-balanced API instances
- **Nginx Load Balancer**: Intelligent request routing
- **Health Checks**: Automatic failover and recovery
- **Rate Limiting**: Per-endpoint rate limiting

## üöÄ Quick Start

### Prerequisites
- Docker and Docker Compose
- 8GB+ RAM
- 4+ CPU cores
- 50GB+ disk space

### 1. Deploy the Scaled System

```bash
# Clone the repository
git clone <repository-url>
cd CustomerCareGPT

# Set your Gemini API key
export GEMINI_API_KEY="your-gemini-api-key-here"

# Deploy the scaled system
./deploy_scaled.sh
```

### 2. Verify Deployment

```bash
# Check system health
curl http://localhost:8000/health/detailed

# Run performance test
cd backend
python performance_test.py --rag-queries 100 --concurrent-users 10
```

### 3. Access Services

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/api/docs
- **Health Check**: http://localhost:8000/health
- **Metrics**: http://localhost:8000/metrics
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/admin)

## üìä Monitoring & Observability

### Health Checks
- **Liveness Probe**: `/health` - Basic system health
- **Readiness Probe**: `/ready` - System ready to accept traffic
- **Detailed Health**: `/health/detailed` - Comprehensive system status

### Metrics
- **Prometheus Metrics**: Available at `/metrics`
- **Custom Metrics**: RAG queries, response times, cache hit rates
- **System Metrics**: CPU, memory, database connections
- **Business Metrics**: User activity, query patterns

### Logging
- **Structured Logging**: JSON format with context
- **Log Levels**: DEBUG, INFO, WARN, ERROR
- **Centralized Logging**: All services log to stdout

## üîß Configuration

### Environment Variables

```bash
# Database
DATABASE_URL=postgresql://user:pass@postgres:5432/db
READ_REPLICA_URLS=postgresql://user:pass@postgres-read:5432/db

# Redis
REDIS_URL=redis://redis:6379
REDIS_MAX_CONNECTIONS=100

# Vector Database
CHROMA_URL=http://chromadb:8000

# API
GEMINI_API_KEY=your-api-key
ENVIRONMENT=production
LOG_LEVEL=INFO

# Scaling
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=30
```

### Scaling Configuration

```yaml
# docker-compose.scale.yml
services:
  api:
    replicas: 3  # Scale API instances
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
  
  worker:
    replicas: 2  # Scale background workers
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
```

## üß™ Performance Testing

### Run Performance Tests

```bash
# Full test suite
python performance_test.py

# Specific tests
python performance_test.py --rag-queries 1000 --concurrent-users 50
python performance_test.py --document-uploads 100 --concurrent-uploads 10
python performance_test.py --simulate-users 300 --queries-per-user 10
```

### Performance Benchmarks

| Test | Target | Achieved |
|------|--------|----------|
| RAG Queries | 1000 queries, 50 concurrent | ‚úÖ 95%+ success rate |
| Response Time | < 3 seconds | ‚úÖ 1-3 seconds avg |
| Document Upload | 100 uploads, 10 concurrent | ‚úÖ 90%+ success rate |
| Concurrent Users | 300 users, 10 queries each | ‚úÖ 85%+ success rate |

## üîÑ Scaling Operations

### Horizontal Scaling

```bash
# Scale API instances
docker-compose -f docker-compose.scale.yml up -d --scale api=5

# Scale workers
docker-compose -f docker-compose.scale.yml up -d --scale worker=4

# Scale queue workers
docker-compose -f docker-compose.scale.yml up -d --scale rq-worker=3
```

### Vertical Scaling

```yaml
# Increase resource limits
deploy:
  resources:
    limits:
      memory: 4G  # Increase from 2G
      cpus: '2.0'  # Increase from 1.0
```

### Database Scaling

```bash
# Add read replicas
# Update READ_REPLICA_URLS in environment
# Restart services
docker-compose -f docker-compose.scale.yml restart
```

## üõ†Ô∏è Maintenance

### Health Monitoring

```bash
# Check system health
curl http://localhost:8000/health/detailed

# View logs
docker-compose -f docker-compose.scale.yml logs -f

# Check resource usage
docker stats
```

### Backup & Recovery

```bash
# Backup database
docker-compose -f docker-compose.scale.yml exec postgres pg_dump -U customercaregpt customercaregpt > backup.sql

# Backup Redis
docker-compose -f docker-compose.scale.yml exec redis redis-cli BGSAVE

# Backup ChromaDB
docker-compose -f docker-compose.scale.yml exec chromadb tar -czf /chroma/backup.tar.gz /chroma/chroma
```

### Updates

```bash
# Update system
git pull
docker-compose -f docker-compose.scale.yml build --no-cache
docker-compose -f docker-compose.scale.yml up -d
```

## üö® Troubleshooting

### Common Issues

1. **High Memory Usage**
   - Check Redis memory usage
   - Monitor database connections
   - Review worker memory limits

2. **Slow Response Times**
   - Check cache hit rates
   - Monitor database performance
   - Review queue lengths

3. **Service Failures**
   - Check circuit breaker status
   - Review health check endpoints
   - Monitor error logs

### Debug Commands

```bash
# Check service status
docker-compose -f docker-compose.scale.yml ps

# View specific service logs
docker-compose -f docker-compose.scale.yml logs api

# Check resource usage
docker-compose -f docker-compose.scale.yml top

# Access service shell
docker-compose -f docker-compose.scale.yml exec api bash
```

## üìà Performance Optimization

### Database Optimization
- Monitor slow queries
- Add missing indexes
- Optimize connection pooling
- Review query patterns

### Caching Optimization
- Monitor cache hit rates
- Adjust TTL values
- Review cache eviction policies
- Optimize cache keys

### Load Balancing
- Monitor upstream health
- Adjust load balancing algorithm
- Review rate limiting rules
- Optimize timeout values

## üîí Security

### Security Features
- **Security Headers**: XSS, CSRF protection
- **Input Validation**: Request sanitization
- **Rate Limiting**: Per-endpoint limits
- **Authentication**: JWT-based auth
- **CORS**: Configurable origins

### Security Monitoring
- Monitor failed authentication attempts
- Review rate limiting hits
- Check for suspicious patterns
- Monitor error rates

## üìû Support

### Getting Help
- Check health endpoints
- Review logs
- Run performance tests
- Monitor metrics

### Performance Issues
- Run performance test suite
- Check system resources
- Review configuration
- Monitor service health

---

## üéâ Success Metrics

Your CustomerCareGPT scaled system is ready when:

- ‚úÖ **Health Checks**: All services report healthy
- ‚úÖ **Performance Tests**: 95%+ success rate on RAG queries
- ‚úÖ **Response Times**: < 3 seconds average
- ‚úÖ **Concurrent Users**: 200+ users supported
- ‚úÖ **File Processing**: 50+ documents/minute
- ‚úÖ **Monitoring**: Prometheus and Grafana accessible
- ‚úÖ **Logging**: Structured logs with context

**üéØ Your system can now serve 300+ business owners with 5,000+ customers and 30,000-50,000 queries per day!**
